<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>OVN Gateway High Availability Plan &mdash; Open vSwitch 2.6.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.6.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Open vSwitch 2.6.0 documentation" href="../index.html" />
    <link rel="up" title="Open vSwitch Deep Dive" href="index.html" />
    <link rel="next" title="How-to Guides" href="../howto/index.html" />
    <link rel="prev" title="Testing" href="testing.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../howto/index.html" title="How-to Guides"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="testing.html" title="Testing"
             accesskey="P">previous</a> |</li>
        <li><a href="../contents.html">Open vSwitch 2.6.0 documentation</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">Open vSwitch Deep Dive</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="ovn-gateway-high-availability-plan">
<h1>OVN Gateway High Availability Plan<a class="headerlink" href="#ovn-gateway-high-availability-plan" title="Permalink to this headline">¶</a></h1>
<div class="highlight-python"><div class="highlight"><pre>OVN Gateway

     +---------------------------+
     |                           |
     |     External Network      |
     |                           |
     +-------------^-------------+
                   |
                   |
             +-----------+
             |           |
             |  Gateway  |
             |           |
             +-----------+
                   ^
                   |
                   |
     +-------------v-------------+
     |                           |
     |    OVN Virtual Network    |
     |                           |
     +---------------------------+
</pre></div>
</div>
<p>The OVN gateway is responsible for shuffling traffic between the tunneled
overlay network (governed by ovn-northd), and the legacy physical network.  In
a naive implementation, the gateway is a single x86 server, or hardware VTEP.
For most deployments, a single system has enough forwarding capacity to service
the entire virtualized network, however, it introduces a single point of
failure.  If this system dies, the entire OVN deployment becomes unavailable.
To mitigate this risk, an HA solution is critical &#8211; by spreading
responsibility across multiple systems, no single server failure can take down
the network.</p>
<p>An HA solution is both critical to the manageability of the system, and
extremely difficult to get right.  The purpose of this document, is to propose
a plan for OVN Gateway High Availability which takes into account our past
experience building similar systems.  It should be considered a fluid changing
proposal, not a set-in-stone decree.</p>
<div class="section" id="basic-architecture">
<h2>Basic Architecture<a class="headerlink" href="#basic-architecture" title="Permalink to this headline">¶</a></h2>
<p>In an OVN deployment, the set of hypervisors and network elements operating
under the guidance of ovn-northd are in what&#8217;s called &#8220;logical space&#8221;.  These
servers use VXLAN, STT, or Geneve to communicate, oblivious to the details of
the underlying physical network.  When these systems need to communicate with
legacy networks, traffic must be routed through a Gateway which translates from
OVN controlled tunnel traffic, to raw physical network traffic.</p>
<p>Since the gateway is typically the only system with a connection to the
physical network all traffic between logical space and the WAN must travel
through it.  This makes it a critical single point of failure &#8211; if the gateway
dies, communication with the WAN ceases for all systems in logical space.</p>
<p>To mitigate this risk, multiple gateways should be run in a &#8220;High Availability
Cluster&#8221; or &#8220;HA Cluster&#8221;.  The HA cluster will be responsible for performing
the duties of a gateways,  while being able to recover gracefully from
individual member failures.</p>
<div class="highlight-python"><div class="highlight"><pre>OVN Gateway HA Cluster

         +---------------------------+
         |                           |
         |     External Network      |
         |                           |
         +-------------^-------------+
                       |
                       |
+----------------------v----------------------+
|                                             |
|          High Availability Cluster          |
|                                             |
| +-----------+  +-----------+  +-----------+ |
| |           |  |           |  |           | |
| |  Gateway  |  |  Gateway  |  |  Gateway  | |
| |           |  |           |  |           | |
| +-----------+  +-----------+  +-----------+ |
+----------------------^----------------------+
                       |
                       |
         +-------------v-------------+
         |                           |
         |    OVN Virtual Network    |
         |                           |
         +---------------------------+
</pre></div>
</div>
<div class="section" id="l2-vs-l3-high-availability">
<h3>L2 vs L3 High Availability<a class="headerlink" href="#l2-vs-l3-high-availability" title="Permalink to this headline">¶</a></h3>
<p>In order to achieve this goal, there are two broad approaches one can take.
The HA cluster can appear to the network like a giant Layer 2 Ethernet Switch,
or like a giant IP Router. These approaches are called L2HA, and L3HA
respectively.  L2HA allows ethernet broadcast domains to extend into logical
space, a significant advantage, but this comes at a cost.  The need to avoid
transient L2 loops during failover significantly complicates their design.  On
the other hand, L3HA works for most use cases, is simpler, and fails more
gracefully.  For these reasons, it is suggested that OVN supports an L3HA
model, leaving L2HA for future work (or third party VTEP providers).  Both
models are discussed further below.</p>
</div>
</div>
<div class="section" id="l3ha">
<h2>L3HA<a class="headerlink" href="#l3ha" title="Permalink to this headline">¶</a></h2>
<p>In this section, we&#8217;ll work through a basic simple L3HA implementation, on top
of which we&#8217;ll gradually build more sophisticated features explaining their
motivations and implementations as we go.</p>
<div class="section" id="naive-active-backup">
<h3>Naive active-backup<a class="headerlink" href="#naive-active-backup" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s assume that there are a collection of logical routers which a tenant has
asked for, our task is to schedule these logical routers on one of N gateways,
and gracefully redistribute the routers on gateways which have failed.  The
absolute simplest way to achieve this is what we&#8217;ll call &#8220;naive-active-backup&#8221;.</p>
<div class="highlight-python"><div class="highlight"><pre>Naive Active Backup HA Implementation

+----------------+   +----------------+
| Leader         |   | Backup         |
|                |   |                |
|      A B C     |   |                |
|                |   |                |
+----+-+-+-+----++   +-+--------------+
     ^ ^ ^ ^    |      |
     | | | |    |      |
     | | | |  +-+------+---+
     + + + +  | ovn-northd |
     Traffic  +------------+
</pre></div>
</div>
<p>In a naive active-backup, one of the Gateways is chosen (arbitrarily) as a
leader.  All logical routers (A, B, C in the figure), are scheduled on this
leader gateway and all traffic flows through it.  ovn-northd monitors this
gateway via OpenFlow echo requests (or some equivalent), and if the gateway
dies, it recreates the routers on one of the backups.</p>
<p>This approach basically works in most cases and should likely be the starting
point for OVN &#8211; it&#8217;s strictly better than no HA solution and is a good
foundation for more sophisticated solutions.  That said, it&#8217;s not without it&#8217;s
limitations. Specifically, this approach doesn&#8217;t coordinate with the physical
network to minimize disruption during failures, and it tightly couples failover
to ovn-northd (we&#8217;ll discuss why this is bad in a bit), and wastes resources by
leaving backup gateways completely unutilized.</p>
<div class="section" id="router-failover">
<h4>Router Failover<a class="headerlink" href="#router-failover" title="Permalink to this headline">¶</a></h4>
<p>When ovn-northd notices the leader has died and decides to migrate routers to a
backup gateway, the physical network has to be notified to direct traffic to
the new gateway.  Otherwise, traffic could be blackholed for longer than
necessary making failovers worse than they need to be.</p>
<p>For now, let&#8217;s assume that OVN requires all gateways to be on the same IP
subnet on the physical network.  If this isn&#8217;t the case, gateways would need to
participate in routing protocols to orchestrate failovers, something which is
difficult and out of scope of this document.</p>
<p>Since all gateways are on the same IP subnet, we simply need to worry about
updating the MAC learning tables of the Ethernet switches on that subnet.
Presumably, they all have entries for each logical router pointing to the old
leader.  If these entries aren&#8217;t updated, all traffic will be sent to the (now
defunct) old leader, instead of the new one.</p>
<p>In order to mitigate this issue, it&#8217;s recommended that the new gateway sends a
Reverse ARP (RARP) onto the physical network for each logical router it now
controls.  A Reverse ARP is a benign protocol used by many hypervisors when
virtual machines migrate to update L2 forwarding tables.  In this case, the
ethernet source address of the RARP is that of the logical router it
corresponds to, and its destination is the broadcast address.  This causes the
RARP to travel to every L2 switch in the broadcast domain, updating forwarding
tables accordingly.  This strategy is recommended in all failover mechanisms
discussed in this document &#8211; when a router newly boots on a new leader, it
should RARP its MAC address.</p>
</div>
</div>
<div class="section" id="controller-independent-active-backup">
<h3>Controller Independent Active-backup<a class="headerlink" href="#controller-independent-active-backup" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre>Controller Independent Active-Backup Implementation

+----------------+   +----------------+
| Leader         |   | Backup         |
|                |   |                |
|      A B C     |   |                |
|                |   |                |
+----------------+   +----------------+
     ^ ^ ^ ^
     | | | |
     | | | |
     + + + +
     Traffic
</pre></div>
</div>
<p>The fundamental problem with naive active-backup, is it tightly couples the
failover solution to ovn-northd.  This can significantly increase downtime in
the event of a failover as the (often already busy) ovn-northd controller has
to recompute state for the new leader. Worse, if ovn-northd goes down, we can&#8217;t
perform gateway failover at all.  This violates the principle that control
plane outages should have no impact on dataplane functionality.</p>
<p>In a controller independent active-backup configuration, ovn-northd is
responsible for initial configuration while the HA cluster is responsible for
monitoring the leader, and failing over to a backup if necessary.  ovn-northd
sets HA policy, but doesn&#8217;t actively participate when failovers occur.</p>
<p>Of course, in this model, ovn-northd is not without some responsibility.  Its
role is to pre-plan what should happen in the event of a failure, leaving it to
the individual switches to execute this plan.  It does this by assigning each
gateway a unique leadership priority.  Once assigned, it communicates this
priority to each node it controls.  Nodes use the leadership priority to
determine which gateway in the cluster is the active leader by using a simple
metric: the leader is the gateway that is healthy, with the highest priority.
If that gateway goes down, leadership falls to the next highest priority, and
conversely, if a new gateway comes up with a higher priority, it takes over
leadership.</p>
<p>Thus, in this model, leadership of the HA cluster is determined simply by the
status of its members.  Therefore if we can communicate the status of each
gateway to each transport node, they can individually figure out which is the
leader, and direct traffic accordingly.</p>
<div class="section" id="tunnel-monitoring">
<h4>Tunnel Monitoring<a class="headerlink" href="#tunnel-monitoring" title="Permalink to this headline">¶</a></h4>
<p>Since in this model leadership is determined exclusively by the health status
of member gateways, a key problem is how do we communicate this information to
the relevant transport nodes.  Luckily, we can do this fairly cheaply using
tunnel monitoring protocols like BFD.</p>
<p>The basic idea is pretty straightforward.  Each transport node maintains a
tunnel to every gateway in the HA cluster (not just the leader).  These tunnels
are monitored using the BFD protocol to see which are alive.  Given this
information, hypervisors can trivially compute the highest priority live
gateway, and thus the leader.</p>
<p>In practice, this leadership computation can be performed trivially using the
bundle or group action.  Rather than using OpenFlow to simply output to the
leader, all gateways could be listed in an active-backup bundle action ordered
by their priority.  The bundle action will automatically take into account the
tunnel monitoring status to output the packet to the highest priority live
gateway.</p>
</div>
<div class="section" id="inter-gateway-monitoring">
<h4>Inter-Gateway Monitoring<a class="headerlink" href="#inter-gateway-monitoring" title="Permalink to this headline">¶</a></h4>
<p>One somewhat subtle aspect of this model, is that failovers are not globally
atomic.  When a failover occurs, it will take some time for all hypervisors to
notice and adjust accordingly.  Similarly, if a new high priority Gateway comes
up, it may take some time for all hypervisors to switch over to the new leader.
In order to avoid confusing the physical network, under these circumstances
it&#8217;s important for the backup gateways to drop traffic they&#8217;ve received
erroneously.  In order to do this, each Gateway must know whether or not it is,
in fact active.  This can be achieved by creating a mesh of tunnels between
gateways.  Each gateway monitors the other gateways its cluster to determine
which are alive, and therefore whether or not that gateway happens to be the
leader.  If leading, the gateway forwards traffic normally, otherwise it drops
all traffic.</p>
</div>
<div class="section" id="gateway-leadership-resignation">
<h4>Gateway Leadership Resignation<a class="headerlink" href="#gateway-leadership-resignation" title="Permalink to this headline">¶</a></h4>
<p>Sometimes a gateway may be healthy, but still may not be suitable to lead the
HA cluster.  This could happen for several reasons including:</p>
<ul class="simple">
<li>The physical network is unreachable</li>
<li>BFD (or ping) has detected the next hop router is unreachable</li>
<li>The Gateway recently booted and isn&#8217;t fully configured</li>
</ul>
<p>In this case, the Gateway should resign leadership by holding its tunnels down
using the <tt class="docutils literal"><span class="pre">other_config:cpath_down</span></tt> flag.  This indicates to participating
hypervisors and Gateways that this gateway should be treated as if it&#8217;s down,
even though its tunnels are still healthy.</p>
</div>
</div>
<div class="section" id="router-specific-active-backup">
<h3>Router Specific Active-Backup<a class="headerlink" href="#router-specific-active-backup" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre>Router Specific Active-Backup

+----------------+ +----------------+
|                | |                |
|      A C       | |     B D E      |
|                | |                |
+----------------+ +----------------+
              ^ ^   ^ ^
              | |   | |
              | |   | |
              + +   + +
               Traffic
</pre></div>
</div>
<p>Controller independent active-backup is a great advance over naive
active-backup, but it still has one glaring problem &#8211; it under-utilizes the
backup gateways.  In ideal scenario, all traffic would split evenly among the
live set of gateways.  Getting all the way there is somewhat tricky, but as a
step in the direction, one could use the &#8220;Router Specific Active-Backup&#8221;
algorithm.  This algorithm looks a lot like active-backup on a per logical
router basis, with one twist.  It chooses a different active Gateway for each
logical router.  Thus, in situations where there are several logical routers,
all with somewhat balanced load, this algorithm performs better.</p>
<p>Implementation of this strategy is quite straightforward if built on top of
basic controller independent active-backup.  On a per logical router basis, the
algorithm is the same, leadership is determined by the liveness of the
gateways.  The key difference here is that the gateways must have a different
leadership priority for each logical router.  These leadership priorities can
be computed by ovn-northd just as they had been in the controller independent
active-backup model.</p>
<p>Once we have these per logical router priorities, they simply need be
communicated to the members of the gateway cluster and the hypervisors.  The
hypervisors in particular, need simply have an active-backup bundle action (or
group action) per logical router listing the gateways in priority order for
<em>that router</em>, rather than having a single bundle action shared for all the
routers.</p>
<p>Additionally, the gateways need to be updated to take into account individual
router priorities.  Specifically, each gateway should drop traffic of backup
routers it&#8217;s running, and forward traffic of active gateways, instead of simply
dropping or forwarding everything.  This should likely be done by having
ovn-controller recompute OpenFlow for the gateway, though other options exist.</p>
<p>The final complication is that ovn-northd&#8217;s logic must be updated to choose
these per logical router leadership priorities in a more sophisticated manner.
It doesn&#8217;t matter much exactly what algorithm it chooses to do this, beyond
that it should provide good balancing in the common case.  I.E. each logical
routers priorities should be different enough that routers balance to different
gateways even when failures occur.</p>
<div class="section" id="preemption">
<h4>Preemption<a class="headerlink" href="#preemption" title="Permalink to this headline">¶</a></h4>
<p>In an active-backup setup, one issue that users will run into is that of
gateway leader preemption.  If a new Gateway is added to a cluster, or for some
reason an existing gateway is rebooted, we could end up in a situation where
the newly activated gateway has higher priority than any other in the HA
cluster.  In this case, as soon as that gateway appears, it will preempt
leadership from the currently active leader causing an unnecessary failover.
Since failover can be quite expensive, this preemption may be undesirable.</p>
<p>The controller can optionally avoid preemption by cleverly tweaking the
leadership priorities.  For each router, new gateways should be assigned
priorities that put them second in line or later when they eventually come up.
Furthermore, if a gateway goes down for a significant period of time, its old
leadership priorities should be revoked and new ones should be assigned as if
it&#8217;s a brand new gateway.  Note that this should only happen if a gateway has
been down for a while (several minutes), otherwise a flapping gateway could
have wide ranging, unpredictable, consequences.</p>
<p>Note that preemption avoidance should be optional depending on the deployment.
One necessarily sacrifices optimal load balancing to satisfy these requirements
as new gateways will get no traffic on boot.  Thus, this feature represents a
trade-off which must be made on a per installation basis.</p>
</div>
</div>
<div class="section" id="fully-active-active-ha">
<h3>Fully Active-Active HA<a class="headerlink" href="#fully-active-active-ha" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre>Fully Active-Active HA

+----------------+ +----------------+
|                | |                |
|   A B C D E    | |    A B C D E   |
|                | |                |
+----------------+ +----------------+
              ^ ^   ^ ^
              | |   | |
              | |   | |
              + +   + +
               Traffic
</pre></div>
</div>
<p>The final step in L3HA is to have true active-active HA.  In this scenario each
router has an instance on each Gateway, and a mechanism similar to ECMP is used
to distribute traffic evenly among all instances.  This mechanism would require
Gateways to participate in routing protocols with the physical network to
attract traffic and alert of failures.  It is out of scope of this document,
but may eventually be necessary.</p>
</div>
</div>
<div class="section" id="l2ha">
<h2>L2HA<a class="headerlink" href="#l2ha" title="Permalink to this headline">¶</a></h2>
<p>L2HA is very difficult to get right.  Unlike L3HA, where the consequences of
problems are minor, in L2HA if two gateways are both transiently active, an L2
loop triggers and a broadcast storm results.  In practice to get around this,
gateways end up implementing an overly conservative &#8220;when in doubt drop all
traffic&#8221; policy, or they implement something like MLAG.</p>
<p>MLAG has multiple gateways work together to pretend to be a single L2 switch
with a large LACP bond.  In principle, it&#8217;s the right solution to the problem
as it solves the broadcast storm problem, and has been deployed successfully in
other contexts.  That said, it&#8217;s difficult to get right and not recommended.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../contents.html">
              <img class="logo" src="../_static/logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../contents.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">OVN Gateway High Availability Plan</a><ul>
<li><a class="reference internal" href="#basic-architecture">Basic Architecture</a><ul>
<li><a class="reference internal" href="#l2-vs-l3-high-availability">L2 vs L3 High Availability</a></li>
</ul>
</li>
<li><a class="reference internal" href="#l3ha">L3HA</a><ul>
<li><a class="reference internal" href="#naive-active-backup">Naive active-backup</a><ul>
<li><a class="reference internal" href="#router-failover">Router Failover</a></li>
</ul>
</li>
<li><a class="reference internal" href="#controller-independent-active-backup">Controller Independent Active-backup</a><ul>
<li><a class="reference internal" href="#tunnel-monitoring">Tunnel Monitoring</a></li>
<li><a class="reference internal" href="#inter-gateway-monitoring">Inter-Gateway Monitoring</a></li>
<li><a class="reference internal" href="#gateway-leadership-resignation">Gateway Leadership Resignation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#router-specific-active-backup">Router Specific Active-Backup</a><ul>
<li><a class="reference internal" href="#preemption">Preemption</a></li>
</ul>
</li>
<li><a class="reference internal" href="#fully-active-active-ha">Fully Active-Active HA</a></li>
</ul>
</li>
<li><a class="reference internal" href="#l2ha">L2HA</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="testing.html"
                        title="previous chapter">Testing</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../howto/index.html"
                        title="next chapter">How-to Guides</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/topics/high-availability.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../howto/index.html" title="How-to Guides"
             >next</a> |</li>
        <li class="right" >
          <a href="testing.html" title="Testing"
             >previous</a> |</li>
        <li><a href="../contents.html">Open vSwitch 2.6.0 documentation</a> &raquo;</li>
          <li><a href="index.html" >Open vSwitch Deep Dive</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2016, The Open vSwitch Development Community.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>